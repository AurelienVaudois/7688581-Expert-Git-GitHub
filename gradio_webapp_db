# email_classification_app.py
"""
Webâ€‘app Gradio pour la **classification assistÃ©e par LLM** et lâ€™Ã©valuation de mails.

FonctionnalitÃ©sÂ :
1. **Import initial automatique** dâ€™un fichier Excel (dÃ©fini par le dÃ©veloppeur) â†’ base SQLite.
2. Parcours dâ€™exemples, appel LLM pour obtenir la prÃ©diction (colonne `prediction`).
3. Validation/InvalidaÂ­tion + commentaire utilisateur â†’ colonnes `eval_status`, `eval_comment`.
4. Persistance totale : toute mise Ã  jour est immÃ©diatement commitÃ©e dans le fichier `emails.db`.

> â„¹ï¸Â Lâ€™utilisateur **nâ€™a aucun contrÃ´le** sur lâ€™importâ€¯; il ne peut que sÃ©lectionner un exemple, classifier et Ã©valuer.

PrÃ©requisÂ :
```bash
pip install gradio pandas openpyxl openai python-dotenv
```
â€“ Placez votre clÃ© dans une variable dâ€™environnement `OPENAI_API_KEY` ou un fichier `.env`Â (`pythonâ€‘dotenv` la lira automatiquement).
"""

from __future__ import annotations

import os
import re
import sqlite3
from pathlib import Path
from typing import List, Tuple

import gradio as gr
import openai
import pandas as pd
from dotenv import load_dotenv

# ---------------------------------------------------------------------------
# 0. Configuration
# ---------------------------------------------------------------------------
DB_PATH = Path("emails.db")             # Base persistance
EXCEL_PATH = Path("mails.xlsx")         # Fichier source choisi par *vous*

LLM_MODEL = "gpt-4o-mini"               # Nom du modÃ¨le OpenAI Ã  utiliser
SYSTEM_PROMPT = (
    "Vous Ãªtes un systÃ¨me de classification dâ€™eâ€‘mails professionnel. "
    "Vous recevez le corps dâ€™un mail (champ message_clean) et vous devez renvoyer "
    "uniquement le code de catÃ©gorie fonctionnelle attendu, sans explications."
)

# Charger la clÃ© API
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# Colonnes ajoutÃ©es pour le workflow
EXTRA_COLS = ["prediction", "eval_status", "eval_comment"]

# ---------------------------------------------------------------------------
# 1. Import (une fois) Excel âžœ SQLite
# ---------------------------------------------------------------------------

def import_excel_once() -> None:
    """Si la base nâ€™existe pas, crÃ©e `emails.db` Ã  partir de `EXCEL_PATH`."""
    if DB_PATH.exists():
        return  # Rien Ã  faire

    if not EXCEL_PATH.exists():
        raise FileNotFoundError(
            f"Fichier Excel source absentÂ : {EXCEL_PATH}. Placezâ€‘le puis relancez."
        )

    print(f"ðŸš€ PremiÃ¨re initialisation : import de {EXCEL_PATH} â†’ {DB_PATH}")
    df = pd.read_excel(EXCEL_PATH)
    df.columns = [re.sub(r"\s+", "_", c).lower() for c in df.columns]
    for col in EXTRA_COLS:
        if col not in df.columns:
            df[col] = None
    with sqlite3.connect(DB_PATH) as conn:
        df.to_sql("emails", conn, if_exists="replace", index=False)
    print("âœ… Base crÃ©Ã©e.")

# ---------------------------------------------------------------------------
# 2. Fonctions utilitaires DB
# ---------------------------------------------------------------------------

def fetch_choices(limit: int = 100) -> List[Tuple[int, str]]:
    with sqlite3.connect(DB_PATH) as conn:
        df = pd.read_sql_query(
            "SELECT rowid AS id, subject FROM emails LIMIT ?", conn, params=(limit,)
        )
    return [(int(r.id), r.subject) for r in df.itertuples()]


def load_email(row_id: int) -> pd.Series:
    with sqlite3.connect(DB_PATH) as conn:
        df = pd.read_sql_query(
            "SELECT rowid AS id, * FROM emails WHERE rowid = ?", conn, params=(row_id,)
        )
    if df.empty:
        raise ValueError(f"Mail id={row_id} introuvable")
    return df.iloc[0]


def save_prediction(row_id: int, prediction: str) -> None:
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute(
            "UPDATE emails SET prediction = ? WHERE rowid = ?", (prediction, row_id)
        )
        conn.commit()


def save_evaluation(row_id: int, status: str, comment: str) -> None:
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute(
            "UPDATE emails SET eval_status = ?, eval_comment = ? WHERE rowid = ?",
            (status, comment, row_id),
        )
        conn.commit()

# ---------------------------------------------------------------------------
# 3. Appel LLM
# ---------------------------------------------------------------------------

def classify(text: str) -> str:
    if not openai.api_key:
        return "<API key manquante>"
    try:
        response = openai.ChatCompletion.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": text},
            ],
            temperature=0,
        )
        label = response.choices[0].message["content"].strip()
        return label
    except Exception as exc:
        return f"Erreur LLMÂ : {exc}"

# ---------------------------------------------------------------------------
# 4. Interface Gradio
# ---------------------------------------------------------------------------

def build_interface() -> gr.Blocks:
    with gr.Blocks(title="LLM Mail Classifier") as demo:
        gr.Markdown("## SÃ©lectionnez un mail, lancez la classification, Ã©valuez")

        example_choice = gr.Dropdown(
            label="Exemples (id â€“ subject)",
            choices=[f"{i} â€“ {s}" for i, s in fetch_choices()],
            interactive=True,
        )
        selected_id = gr.State(value=None)

        mail_input = gr.Textbox(
            label="message_clean", lines=15, interactive=False  # lecture seule
        )

        classify_btn = gr.Button("Classifier avec LLM")
        prediction_out = gr.Textbox(label="Prediction", interactive=False)

        gr.Markdown("### Ã‰valuation humaine")
        with gr.Row():
            valider = gr.Button("Valider", variant="primary")
            invalider = gr.Button("Invalider", variant="stop")
            eval_state = gr.State(value=None)
        comment_box = gr.Textbox(label="Commentaire", lines=3)
        save_btn = gr.Button("Enregistrer", variant="secondary")
        save_msg = gr.Markdown()

        # Callback sÃ©lection d'exemple
        def on_select(choice: str):
            if not choice:
                return gr.update(), None, None
            row_id = int(choice.split(" â€“ ")[0])
            row = load_email(row_id)
            return gr.update(value=row.message_clean), row_id, row.prediction

        example_choice.change(
            fn=on_select,
            inputs=example_choice,
            outputs=[mail_input, selected_id, prediction_out],
        )

        # Classification + persistance
        def on_classify(text: str, row_id: int | None):
            pred = classify(text)
            if row_id is not None and not pred.startswith("<"):
                save_prediction(row_id, pred)
            return pred

        classify_btn.click(on_classify, inputs=[mail_input, selected_id], outputs=prediction_out)

        valider.click(lambda: "valider", None, eval_state)
        invalider.click(lambda: "invalider", None, eval_state)

        def on_save(row_id: int | None, status: str | None, comment: str):
            if row_id is None:
                return "âŒ SÃ©lectionnez un mail d'abord."
            if status not in {"valider", "invalider"}:
                return "âŒ Cliquez sur Valider/Invalider avant."
            save_evaluation(row_id, status, comment)
            return "âœ… Ã‰valuation enregistrÃ©e."

        save_btn.click(on_save, inputs=[selected_id, eval_state, comment_box], outputs=save_msg)

    return demo

# ---------------------------------------------------------------------------
# 5. Main
# ---------------------------------------------------------------------------

def main() -> None:
    import_excel_once()  # fait la base si besoin
    ui = build_interface()
    ui.launch(server_name="0.0.0.0")


if __name__ == "__main__":
    main()
