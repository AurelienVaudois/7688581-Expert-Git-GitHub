import pandas as pd
import outlines

# Charger le modèle
model = outlines.models.transformers("microsoft/Phi-3-mini-4k-instruct")

def classify_verbatims(df, categories):
    """
    Classifie chaque verbatim dans un DataFrame selon des catégories spécifiques.

    Args:
        df (pd.DataFrame): Le DataFrame contenant les verbatims.
        categories (pd.DataFrame): Un DataFrame contenant deux colonnes :
            - "categorie": le nom de la catégorie.
            - "definition": une courte description de la catégorie.

    Returns:
        pd.DataFrame: Le DataFrame d'origine avec des colonnes supplémentaires pour chaque catégorie.
    """
    # Itérer sur chaque catégorie
    for _, row in categories.iterrows():
        category_name = row['categorie']
        category_definition = row['definition']

        # Créer une nouvelle colonne pour la catégorie
        col_name = f"belongs_to_{category_name}"

        def classify(verbatim):
            prompt = f"""
            You are a text-classification assistant. Determine if the following text fits the category below:

            Text: {verbatim}
            Category: {category_name}
            Definition: {category_definition}
            
            Answer 'Yes' or 'No'.
            """

            generator = outlines.generate.choice(model, ["Yes", "No"])
            response = generator(prompt)
            return response == "Yes"

        # Appliquer la fonction de classification
        df[col_name] = df['verbatim'].apply(classify)

    return df

# Exemple d'utilisation
df_verbatims = pd.DataFrame({"verbatim": ["This product is amazing!", "I had a terrible experience.", "Service was okay."]})
df_categories = pd.DataFrame({
    "categorie": ["Positive Experience", "Negative Experience"],
    "definition": ["The text expresses positive sentiment.", "The text expresses negative sentiment."]
})

df_result = classify_verbatims(df_verbatims, df_categories)
print(df_result)

-------++++++++++++++++-------------

import pandas as pd
from sklearn.metrics import classification_report, multilabel_confusion_matrix

def evaluate_performance(df, category_mapping):
    """
    Évalue les performances du modèle en utilisant un mapping entre codes de catégories et noms de colonnes.

    Args:
        df (pd.DataFrame): DataFrame contenant les annotations et prédictions.
        category_mapping (dict): Dictionnaire de correspondance {code: nom_de_colonne}.

    Returns:
        str: Rapport de classification pour chaque catégorie.
    """
    # Extraire les noms des colonnes de prédictions à partir du mapping
    category_columns = list(category_mapping.values())

    # Prétraitement des annotations : Vérifier si chaque code est présent dans les annotations
    true_multilabel = pd.DataFrame({
        category_mapping[code]: df['annotations'].apply(lambda x: category_mapping[code] in x)
        for code in category_mapping
    })

    # Convertir les prédictions "Oui"/"Non" en format binaire
    pred_multilabel = df[category_columns].applymap(lambda x: 1 if x == "Oui" else 0)

    # Calculer les métriques de classification
    report = classification_report(true_multilabel, pred_multilabel, target_names=category_columns)
    confusion_matrices = multilabel_confusion_matrix(true_multilabel, pred_multilabel)

    return report, confusion_matrices

# Exemple d'utilisation
df_example = pd.DataFrame({
    "verbatim": ["Text1", "Text2", "Text3"],
    "annotations": [{"c0201", "c0301"}, {"c0202"}, {"c0301"}],  # True labels
    "Positive Experience": ["Oui", "Non", "Oui"],  # Predictions
    "Negative Experience": ["Non", "Oui", "Non"]   # Predictions
})

# Dictionnaire de correspondance entre codes et noms de colonnes
category_mapping = {
    "c0201": "Positive Experience",
    "c0301": "Negative Experience",
    # Ajoutez d'autres correspondances ici
}

# Évaluation des performances
classification_rep, confusion_matrices = evaluate_performance(df_example, category_mapping)

print(classification_rep)
print(confusion_matrices)

-----------------------------------------------------------------------

import pandas as pd
from sklearn.metrics import precision_score, recall_score, accuracy_score

# Exemple de DataFrame
data = {
    "FBK_VERBATIM": ["changement permanent de conseiller", "retard du train", "conseiller désagréable"],
    "MLC2_CATEG_NIV2": [["c0405"], ["c0401", "c0402"], ["c0403"]],
    "Horaires": ["non", "oui", "non"],
    "Fiabilité": ["non", "oui", "non"],
    "Relation client": ["non", "non", "oui"]
}
df = pd.DataFrame(data)

# Dictionnaire de correspondance des catégories
category_mapping = {
    "Horaires": "c0401",
    "Fiabilité": "c0402",
    "Relation client": "c0403",
    # etc.
}

# Conversion des prédictions en binaire (0 pour 'non', 1 pour 'oui')
categories = list(category_mapping.keys())
for cat in categories:
    df[cat] = df[cat].map({"oui": 1, "non": 0})

# Création des colonnes binaires pour la vérité terrain
for cat, code in category_mapping.items():
    df[f"true_{cat}"] = df["MLC2_CATEG_NIV2"].apply(lambda x: 1 if code in x else 0)

# Calcul des métriques
metrics = {}
for cat in categories:
    true_col = f"true_{cat}"
    pred_col = cat
    precision = precision_score(df[true_col], df[pred_col], zero_division=0)
    recall = recall_score(df[true_col], df[pred_col], zero_division=0)
    accuracy = accuracy_score(df[true_col], df[pred_col])
    metrics[cat] = {"precision": precision, "recall": recall, "accuracy": accuracy}

# Affichage des résultats
metrics_df = pd.DataFrame(metrics).T
metrics_df.index.name = "Category"
import ace_tools as tools; tools.display_dataframe_to_user(name="Performance Metrics for LLM Classification", dataframe=metrics_df)

---------------------------------------------------------

from sklearn.metrics import classification_report
import pandas as pd
import ast

# Exemple de données avec problème dans MLC2_CATEG_NIV2
data = {
    "FBK_VERBATIM": ["changement permanent de conseiller", "retard du train", "conseiller désagréable"],
    "MLC2_CATEG_NIV2": ["['c0405']", "['c0401', 'c0402']", "['c0403']"],
    "Horaires": ["non", "oui", "non"],
    "Fiabilité": ["non", "oui", "non"],
    "Relation client": ["non", "non", "oui"]
}
df = pd.DataFrame(data)

# Correction : conversion des chaînes en listes
df['MLC2_CATEG_NIV2'] = df['MLC2_CATEG_NIV2'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)

# Dictionnaire de correspondance
category_mapping = {
    "Horaires": "c0401",
    "Fiabilité": "c0402",
    "Relation client": "c0403",
}

# Conversion des prédictions en binaire
categories = list(category_mapping.keys())
for cat in categories:
    df[cat] = df[cat].map({"oui": 1, "non": 0})

# Création des colonnes vérité terrain
for cat, code in category_mapping.items():
    df[f"true_{cat}"] = df["MLC2_CATEG_NIV2"].apply(lambda x: 1 if code in x else 0)

# Préparation des données pour le rapport
y_true = df[[f"true_{cat}" for cat in categories]].values  # Vérités terrain
y_pred = df[categories].values  # Prédictions du modèle

# Génération du rapport de classification
report = classification_report(y_true, y_pred, target_names=categories, zero_division=0)

# Affichage du rapport
print(report)

-------------------------------------------------------------------------

import numpy as np
import pandas as pd
from sklearn.metrics import classification_report

# Exemple de données
data = {
    "FBK_VERBATIM": ["exemple 1", "exemple 2", "exemple 3"],
    "MLC2_CATEG_NIV2": [np.array(['c0401', 'c0501']), np.array(['c0503']), np.array(['c0401', 'c0503'])],
    "Horaires": ["oui", "non", "oui"],
    "Fiabilité": ["non", "non", "non"],
    "Relation client": ["non", "oui", "oui"]
}
df = pd.DataFrame(data)

# Dictionnaire des catégories et correspondances
category_mapping = {
    "Horaires": "c0401",
    "Fiabilité": "c0501",
    "Relation client": "c0503",
}

# Liste des catégories uniques à partir du dictionnaire
all_categories = list(category_mapping.values())

# Transformation des vérités terrain (MLC2_CATEG_NIV2) en matrice binaire
def binary_matrix(array_column, categories):
    binary_matrix = np.zeros((len(array_column), len(categories)), dtype=int)
    for i, row in enumerate(array_column):
        for cat in row:
            if cat in categories:
                binary_matrix[i, categories.index(cat)] = 1
    return binary_matrix

# Matrices binaires pour y_true (vérités terrain) et y_pred (prédictions)
y_true = binary_matrix(df['MLC2_CATEG_NIV2'], all_categories)

# Conversion des prédictions en binaire
df['Horaires'] = df['Horaires'].map({"oui": 1, "non": 0})
df['Fiabilité'] = df['Fiabilité'].map({"oui": 1, "non": 0})
df['Relation client'] = df['Relation client'].map({"oui": 1, "non": 0})

# Génération de y_pred à partir des colonnes de prédictions
y_pred = df[list(category_mapping.keys())].values

# Calcul du rapport de classification
report = classification_report(y_true, y_pred, target_names=all_categories, zero_division=0)
print(report)

----------------------------------------------------------------------------------------------------------------------

import pandas as pd
import outlines
import os

model = outlines.models.transformers("microsoft/Phi-3-mini-4k-instruct")

def classify_verbatims(df, categories, output_path="resultats.csv"):
    # Charger des résultats partiels s'ils existent
    if os.path.exists(output_path):
        df_partials = pd.read_csv(output_path)
        # Fusionner sur la clé d'identification (id du verbatim) ou autre
        df = df.merge(df_partials, on="id", how="left", suffixes=("", "_old"))
        # Déplacer les colonnes déjà existantes
        for cat in categories['categorie']:
            if cat in df.columns and f"{cat}_old" in df.columns:
                df[cat] = df[cat].combine_first(df[f"{cat}_old"])
                df.drop(columns=[f"{cat}_old"], inplace=True)

    # Itérer sur chaque catégorie
    for _, row in categories.iterrows():
        category_name = row['categorie']
        category_definition = row['definition']
        col_name = f"{category_name}"

        # Ne traiter que les verbatims non déjà classifiés pour cette catégorie
        mask_to_process = df[col_name].isna() if col_name in df.columns else [True]*len(df)
        
        # Appliquer la classification sur les lignes non traitées
        for idx in df[mask_to_process].index:
            verbatim = df.at[idx, 'verbatim']
            prompt = f"""
            Tu es un expert en analyse de texte et tu indiques si un verbatim client appartient ou non à une catégorie.

            Voici la définition de la catégorie {category_name} : {category_definition}

            Est ce que le verbatim suivant appartient à la catégorie {category_name} ? : {verbatim}
            """
            generator = outlines.generate.choice(model, ["oui", "non"])
            response = generator(prompt)
            # Stocker le résultat
            df.at[idx, col_name] = response

            # Sauvegarde incrémentale (par exemple tous les 100 verbatims)
            if idx % 100 == 0:
                df.to_csv(output_path, index=False)

    # Sauvegarde finale
    df.to_csv(output_path, index=False)
    return df
---------------------------------------------------------------------------------------------------------------

import pandas as pd
import os
import outlines

# Charger le modèle
model = outlines.models.transformers("microsoft/Phi-3-mini-4k-instruct")

def classify(verbatim, category_name, category_definition):
    """
    Classifie un verbatim pour une catégorie donnée.
    Retourne "oui" ou "non".
    """
    prompt = f"""
Tu es un expert en analyse de texte.
Tu dois répondre strictement "oui" ou "non" sans autre texte.

Définition de la catégorie {category_name} : {category_definition}

Le verbatim suivant appartient-il à la catégorie {category_name} ?
"{verbatim}"

Réponds uniquement par "oui" ou "non".
"""
    generator = outlines.generate.choice(model, ["oui", "non"])
    response = generator(prompt)
    return response.strip()

def classify_verbatims(df, categories, output_path="resultats.csv"):
    """
    Classifie chaque verbatim pour chaque catégorie, puis sauvegarde après chaque verbatim.
    
    Args:
        df (pd.DataFrame): doit contenir :
            - 'FBK_VERBATIMS' : identifiant unique du verbatim
            - 'verbatim' : le texte du verbatim
        categories (pd.DataFrame): doit contenir :
            - 'LIB_CATEG' : nom de la catégorie (ex: 'c0401')
            - 'LIB_DESC' : définition textuelle de la catégorie
        output_path (str): chemin pour sauvegarder les résultats partiels et finaux.
    
    Returns:
        pd.DataFrame: Le DataFrame avec une colonne par catégorie (oui/non).
    """

    # Charger des résultats partiels s'ils existent
    if os.path.exists(output_path):
        df_partials = pd.read_csv(output_path)
        # Fusion sur FBK_VERBATIMS
        df = df.merge(df_partials, on="FBK_VERBATIMS", how="left", suffixes=("", "_old"))
        
        # Combiner les colonnes dupliquées (anciennes et nouvelles)
        for cat in categories['LIB_CATEG']:
            if cat in df.columns and f"{cat}_old" in df.columns:
                df[cat] = df[cat].combine_first(df[f"{cat}_old"])
                df.drop(columns=[f"{cat}_old"], inplace=True, errors='ignore')
    else:
        # Vérifier la présence de l'ID
        if "FBK_VERBATIMS" not in df.columns:
            raise ValueError("La colonne 'FBK_VERBATIMS' est requise pour identifier les verbatims.")

# S'assurer que les colonnes pour chaque catégorie existent
    for cat in categories['LIB_CATEG']:
        if cat not in df.columns:
            df[cat] = None

    # Tableau numpy des catégories
    cat_array = categories['LIB_CATEG'].values

    # Itérer sur chaque verbatim
    for idx in df.index:
        row = df.loc[idx]
        # Extraire les valeurs correspondant aux catégories
        # row[cat_array] donne les valeurs des colonnes catégorie pour cette ligne
        row_values = row[cat_array]
        # Boolean mask des catégories manquantes
        missing_mask = row_values.isna().values
        # Catégories manquantes
        missing_cats = cat_array[missing_mask]

        if len(missing_cats) == 0:
            # Toutes les catégories de ce verbatim sont déjà traitées
            continue

        verbatim_text = row['FBK_VERBATIMS']

        # Classifier les catégories manquantes pour ce verbatim
        for cat_code in missing_cats:
            cat_def = categories.loc[categories['LIB_CATEG'] == cat_code, 'LIB_DESC'].iloc[0]
            result = classify(verbatim_text, cat_code, cat_def)
            df.at[idx, cat_code] = result

        # Sauvegarder après avoir traité toutes les catégories de ce verbatim
        df.to_csv(output_path, index=False)

    return df
