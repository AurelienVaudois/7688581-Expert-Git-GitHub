import pandas as pd
import outlines

# Charger le modèle
model = outlines.models.transformers("microsoft/Phi-3-mini-4k-instruct")

def classify_verbatims(df, categories):
    """
    Classifie chaque verbatim dans un DataFrame selon des catégories spécifiques.

    Args:
        df (pd.DataFrame): Le DataFrame contenant les verbatims.
        categories (pd.DataFrame): Un DataFrame contenant deux colonnes :
            - "categorie": le nom de la catégorie.
            - "definition": une courte description de la catégorie.

    Returns:
        pd.DataFrame: Le DataFrame d'origine avec des colonnes supplémentaires pour chaque catégorie.
    """
    # Itérer sur chaque catégorie
    for _, row in categories.iterrows():
        category_name = row['categorie']
        category_definition = row['definition']

        # Créer une nouvelle colonne pour la catégorie
        col_name = f"belongs_to_{category_name}"

        def classify(verbatim):
            prompt = f"""
            You are a text-classification assistant. Determine if the following text fits the category below:

            Text: {verbatim}
            Category: {category_name}
            Definition: {category_definition}
            
            Answer 'Yes' or 'No'.
            """

            generator = outlines.generate.choice(model, ["Yes", "No"])
            response = generator(prompt)
            return response == "Yes"

        # Appliquer la fonction de classification
        df[col_name] = df['verbatim'].apply(classify)

    return df

# Exemple d'utilisation
df_verbatims = pd.DataFrame({"verbatim": ["This product is amazing!", "I had a terrible experience.", "Service was okay."]})
df_categories = pd.DataFrame({
    "categorie": ["Positive Experience", "Negative Experience"],
    "definition": ["The text expresses positive sentiment.", "The text expresses negative sentiment."]
})

df_result = classify_verbatims(df_verbatims, df_categories)
print(df_result)

-------++++++++++++++++-------------

import pandas as pd
from sklearn.metrics import classification_report, multilabel_confusion_matrix

def evaluate_performance(df, category_mapping):
    """
    Évalue les performances du modèle en utilisant un mapping entre codes de catégories et noms de colonnes.

    Args:
        df (pd.DataFrame): DataFrame contenant les annotations et prédictions.
        category_mapping (dict): Dictionnaire de correspondance {code: nom_de_colonne}.

    Returns:
        str: Rapport de classification pour chaque catégorie.
    """
    # Extraire les noms des colonnes de prédictions à partir du mapping
    category_columns = list(category_mapping.values())

    # Prétraitement des annotations : Vérifier si chaque code est présent dans les annotations
    true_multilabel = pd.DataFrame({
        category_mapping[code]: df['annotations'].apply(lambda x: category_mapping[code] in x)
        for code in category_mapping
    })

    # Convertir les prédictions "Oui"/"Non" en format binaire
    pred_multilabel = df[category_columns].applymap(lambda x: 1 if x == "Oui" else 0)

    # Calculer les métriques de classification
    report = classification_report(true_multilabel, pred_multilabel, target_names=category_columns)
    confusion_matrices = multilabel_confusion_matrix(true_multilabel, pred_multilabel)

    return report, confusion_matrices

# Exemple d'utilisation
df_example = pd.DataFrame({
    "verbatim": ["Text1", "Text2", "Text3"],
    "annotations": [{"c0201", "c0301"}, {"c0202"}, {"c0301"}],  # True labels
    "Positive Experience": ["Oui", "Non", "Oui"],  # Predictions
    "Negative Experience": ["Non", "Oui", "Non"]   # Predictions
})

# Dictionnaire de correspondance entre codes et noms de colonnes
category_mapping = {
    "c0201": "Positive Experience",
    "c0301": "Negative Experience",
    # Ajoutez d'autres correspondances ici
}

# Évaluation des performances
classification_rep, confusion_matrices = evaluate_performance(df_example, category_mapping)

print(classification_rep)
print(confusion_matrices)

-----------------------------------------------------------------------

import pandas as pd
from sklearn.metrics import precision_score, recall_score, accuracy_score

# Exemple de DataFrame
data = {
    "FBK_VERBATIM": ["changement permanent de conseiller", "retard du train", "conseiller désagréable"],
    "MLC2_CATEG_NIV2": [["c0405"], ["c0401", "c0402"], ["c0403"]],
    "Horaires": ["non", "oui", "non"],
    "Fiabilité": ["non", "oui", "non"],
    "Relation client": ["non", "non", "oui"]
}
df = pd.DataFrame(data)

# Dictionnaire de correspondance des catégories
category_mapping = {
    "Horaires": "c0401",
    "Fiabilité": "c0402",
    "Relation client": "c0403",
    # etc.
}

# Conversion des prédictions en binaire (0 pour 'non', 1 pour 'oui')
categories = list(category_mapping.keys())
for cat in categories:
    df[cat] = df[cat].map({"oui": 1, "non": 0})

# Création des colonnes binaires pour la vérité terrain
for cat, code in category_mapping.items():
    df[f"true_{cat}"] = df["MLC2_CATEG_NIV2"].apply(lambda x: 1 if code in x else 0)

# Calcul des métriques
metrics = {}
for cat in categories:
    true_col = f"true_{cat}"
    pred_col = cat
    precision = precision_score(df[true_col], df[pred_col], zero_division=0)
    recall = recall_score(df[true_col], df[pred_col], zero_division=0)
    accuracy = accuracy_score(df[true_col], df[pred_col])
    metrics[cat] = {"precision": precision, "recall": recall, "accuracy": accuracy}

# Affichage des résultats
metrics_df = pd.DataFrame(metrics).T
metrics_df.index.name = "Category"
import ace_tools as tools; tools.display_dataframe_to_user(name="Performance Metrics for LLM Classification", dataframe=metrics_df)
